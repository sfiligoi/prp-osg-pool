#
# These worker nodes will be prempted, use with care
#
apiVersion: apps/v1
kind: Deployment
metadata:
  name: osg-wn-cpu-opt4
  namespace: osggpus
  labels: 
    k8s-app: osg-wn-cpu-opt4
spec:
  replicas: 400
  selector:
    matchLabels:
      k8s-app: osg-wn-cpu-opt4
  template:
    metadata: 
      labels:
        k8s-app: osg-wn-cpu-opt4
    spec:
      priorityClassName: opportunistic
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: env
                operator: NotIn
                values:
                - osg
                - I2
      tolerations:
      - effect: NoSchedule
        key: nautilus.io/noceph
        operator: Exists
      containers:
      - name: cvmfs
        image: sfiligoi/prp-osg-pool:wn-cvmfs
        imagePullPolicy: Always
        securityContext:
          privileged: true
          capabilities:
            add: ["SYS_ADMIN"]
          allowPrivilegeEscalation: true
        lifecycle:
          preStop:
            exec:
              command: ["/usr/local/sbin/unmount-and-terminate.sh"]
        env:
        - name: MOUNT_REPOS
          value: "config-osg.opensciencegrid.org,icecube.opensciencegrid.org,oasis.opensciencegrid.org,connect.opensciencegrid.org,singularity.opensciencegrid.org,stash.osgstorage.org,xenon.opensciencegrid.org"
        - name: SQUID_URI
          value: "http://10.98.29.184:3128"
        resources:
           limits:
             memory: 4Gi
             cpu: 1
           requests:
             memory: 0.5Gi
             cpu: 0.1
        volumeMounts:
        - mountPath: /cvmfs
          name:  shared-cvmfs
          mountPropagation: Bidirectional
      - name: osg-wn-cpu
        image: sfiligoi/prp-osg-pool:wn-cpu
        imagePullPolicy: Always
        #command: ["sh", "-c", "sleep infinity"]
        resources:
           limits:
             memory: 13Gi
             cpu: 6
           requests:
             memory: 10Gi
             cpu: 3
             # we will schedule 4 jobs, but expect 75% efficiency
        volumeMounts:
        - name: configpasswd
          mountPath: /var/lock/condor/pool_password
          subPath: pool_password
          readOnly: true
        - name: confighost
          mountPath: /etc/condor/config.d/50_condor_host.config
          subPath: 50_condor_host.config
        - name: configmem
          mountPath: /etc/condor/config.d/02_memory_limits_10g.config
          subPath: 02_memory_limits_10g.config
        - name: configic
          mountPath: /etc/condor/config.d/09_icecube.config
          subPath: 09_icecube.config
        - name: configusers
          mountPath: /usr/local/sbin/add_image_users.sh
          subPath: add_image_users.sh
        - mountPath: /cvmfs
          name:  shared-cvmfs
          mountPropagation: HostToContainer
          readOnly: true
      volumes:
      - name: shared-cvmfs
        emptyDir: {}
      - name: configpasswd
        secret:
          secretName: osg-pool-sdsc-config
          items:
             - key: pool_password
               path: pool_password
          defaultMode: 256
      - name: confighost
        configMap:
          name: osg-wn-prp-config
          items:
             - key: 50_condor_host.config
               path: 50_condor_host.config
      - name: configmem
        configMap:
          name: osg-wn-prp-cpu-config
          items:
             - key: 02_memory_limits_10g.config
               path: 02_memory_limits_10g.config
      - name: configic
        configMap:
          name: osg-wn-prp-cpu-config
          items:
             - key: 09_icecube.config
               path: 09_icecube.config
      - name: configusers
        configMap:
          name: osg-wn-prp-config
          items:
             - key: add_image_users.sh
               path: add_image_users.sh

